{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "461f3475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\MyCase\\\\Projects\\\\DSAI\\\\portfolio\\\\Sales_Forecasting_and_Analytics\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3d5b438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\MyCase\\\\Projects\\\\DSAI\\\\portfolio\\\\Sales_Forecasting_and_Analytics'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a9a721",
   "metadata": {},
   "source": [
    "<p>Itâ€™s a great time to integrate with MLflow to track our training, monitor metrics, and manage experiments more effectively.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e48db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as roshankahaneDSAI\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as roshankahaneDSAI\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"roshankahaneDSAI/Sales_Forecasting_and_Analytics\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"roshankahaneDSAI/Sales_Forecasting_and_Analytics\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository roshankahaneDSAI/Sales_Forecasting_and_Analytics initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository roshankahaneDSAI/Sales_Forecasting_and_Analytics initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run mercurial-koi-145 at: https://dagshub.com/roshankahaneDSAI/Sales_Forecasting_and_Analytics.mlflow/#/experiments/0/runs/0ad6d8b1fa2a45a8a1fa8a877bd6f753\n",
      "ðŸ§ª View experiment at: https://dagshub.com/roshankahaneDSAI/Sales_Forecasting_and_Analytics.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='roshankahaneDSAI', repo_name='Sales_Forecasting_and_Analytics', mlflow=True)\n",
    "\n",
    "import mlflow\n",
    "with mlflow.start_run():\n",
    "  mlflow.log_param('parameter name', 'value')\n",
    "  mlflow.log_metric('metric name', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "551890a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from ml_service.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from ml_service.utils.main_utils import read_yaml, create_directories, save_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d51c86df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ModelBuildingAndEvaluationConfig:\n",
    "    path_of_model: Path\n",
    "    input_train_file: Path\n",
    "    input_test_file: Path\n",
    "    metrics_file: Path\n",
    "    all_params: dict\n",
    "    mlflow_uri: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85cd48b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_filepath: str = CONFIG_FILE_PATH,\n",
    "                 params_filepath: str = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        root_dir = Path(self.config.modelBuildingAndEvaluation.root_dir)\n",
    "        create_directories([root_dir])\n",
    "\n",
    "    def get_modelBuilding_and_evaluation_config(self) -> ModelBuildingAndEvaluationConfig:\n",
    "        \"\"\"Construct the EvaluationConfig object based on modelBuildingAndEvaluation settings.\"\"\"\n",
    "        model_cfg = self.config.modelBuildingAndEvaluation\n",
    "\n",
    "        return ModelBuildingAndEvaluationConfig(\n",
    "            path_of_model=Path(model_cfg.model_file),\n",
    "            input_train_file=Path(model_cfg.input_train_file),\n",
    "            input_test_file=Path(model_cfg.input_test_file),\n",
    "            metrics_file=Path(model_cfg.evaluation_metrics),\n",
    "            all_params=self.params,\n",
    "            mlflow_uri=self.params.get(\"TRACKING_SERVER\", \"\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc6a683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuildingAndEvaluation:\n",
    "    \"\"\"Train, Evaluate Model and Track Results with MLflow.\"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load, sample, and split data into train/val sets.\"\"\"\n",
    "        train_df = pd.read_csv(self.config.input_train_file)\n",
    "        test_df = pd.read_csv(self.config.input_test_file)\n",
    "\n",
    "        # Ensure 'date' is datetime\n",
    "        train_df[\"date\"] = pd.to_datetime(train_df[\"date\"])\n",
    "        # train_df = train_df.sample(n=50000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "        # Split into training and validation\n",
    "        train_split = train_df[train_df[\"date\"].dt.year <= 2016].reset_index(drop=True)\n",
    "        val_split = train_df[train_df[\"date\"].dt.year == 2017].reset_index(drop=True)\n",
    "\n",
    "        cat_columns = [\"family\", \"state\", \"city\", \"type_x\", \"type_y\", \"sales\", \"date\"]\n",
    "        target_col = \"sales\"   # or whatever target is\n",
    "\n",
    "        self.X_train = train_split.drop(columns=cat_columns)\n",
    "        self.y_train = train_split[target_col]\n",
    "\n",
    "        self.X_test = val_split.drop(columns=cat_columns)\n",
    "        self.y_test = val_split[target_col]\n",
    "    \n",
    "    def train_model(self):\n",
    "        \"\"\"Train XGBoost Model based on config parameters.\"\"\"\n",
    "        self.model = XGBRegressor(\n",
    "            random_state=self.config.all_params[\"RANDOM_STATE\"],\n",
    "            n_estimators=self.config.all_params[\"N_ESTIMATORS\"],\n",
    "            learning_rate=self.config.all_params[\"LEARNING_RATE\"],\n",
    "            max_depth=self.config.all_params[\"MAX_DEPTH\"],\n",
    "            subsample=self.config.all_params[\"SUBSAMPLE\"],\n",
    "            colsample_bytree=self.config.all_params[\"COLSAMPLE_BY_TREE\"],\n",
    "            objective=self.config.all_params[\"OBJECTIVE\"]\n",
    "        )\n",
    "\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        # Save trained model\n",
    "        os.makedirs(Path(self.config.path_of_model).parent, exist_ok=True)\n",
    "        joblib.dump(self.model, self.config.path_of_model)\n",
    "\n",
    "    def evaluate(self) -> dict:\n",
    "        \"\"\"Evaluate Model and Save Metrics.\"\"\"\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(self.y_test, y_pred))\n",
    "        mae = mean_absolute_error(self.y_test, y_pred)\n",
    "        rmsle = np.sqrt(np.mean(np.square(np.log1p(np.maximum(y_pred, 0)) - np.log1p(self.y_test))))\n",
    "\n",
    "        metrics = {\"rmse\": rmse, \"mae\": mae, \"rmsle\": rmsle}\n",
    "        save_json(self.config.metrics_file, metrics)\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def log_into_mlflow(self, metrics: dict):\n",
    "        \"\"\"Log Model Parameters and Metrics into MLflow.\"\"\"\n",
    "        mlflow.set_tracking_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "        model_params = {\n",
    "            \"MODEL_TYPE\": self.config.all_params[\"MODEL_TYPE\"],\n",
    "            \"RANDOM_STATE\": self.config.all_params[\"RANDOM_STATE\"],\n",
    "            \"N_ESTIMATORS\": self.config.all_params[\"N_ESTIMATORS\"],\n",
    "            \"LEARNING_RATE\": self.config.all_params[\"LEARNING_RATE\"],\n",
    "            \"MAX_DEPTH\": self.config.all_params[\"MAX_DEPTH\"],\n",
    "            \"SUBSAMPLE\": self.config.all_params[\"SUBSAMPLE\"],\n",
    "            \"COLSAMPLE_BY_TREE\": self.config.all_params[\"COLSAMPLE_BY_TREE\"],\n",
    "            \"REG_ALPHA\": self.config.all_params[\"REG_ALPHA\"],\n",
    "            \"REG_LAMBDA\": self.config.all_params[\"REG_LAMBDA\"],\n",
    "            \"GAMMA\": self.config.all_params[\"GAMMA\"],\n",
    "            \"OBJECTIVE\": self.config.all_params[\"OBJECTIVE\"]\n",
    "        }\n",
    "\n",
    "        signature = infer_signature(self.X_train, self.model.predict(self.X_train))\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(model_params)\n",
    "            mlflow.log_metrics(metrics)\n",
    "\n",
    "            if tracking_url_type_store != \"file\":\n",
    "                mlflow.sklearn.log_model(\n",
    "                    sk_model=self.model,\n",
    "                    name=\"model\",\n",
    "                    registered_model_name=\"Sales_Forecasting_and_Analytics\",\n",
    "                    signature=signature,\n",
    "                    input_example=self.X_train.iloc[:5],  # small sample\n",
    "                )\n",
    "            else:\n",
    "                mlflow.sklearn.log_model(\n",
    "                    sk_model=self.model,\n",
    "                    name=\"model\",\n",
    "                    signature=signature,\n",
    "                    input_example=self.X_train.iloc[:5],\n",
    "                )\n",
    "                \n",
    "    def create_submission(self, test_file, submission_file):\n",
    "        \"\"\"Create Submission File for Kaggle-style prediction.\"\"\"\n",
    "        test_df = pd.read_csv(test_file)\n",
    "\n",
    "        # Ensure columns match training\n",
    "        missing_cols = set(self.X_train.columns) - set(test_df.columns)\n",
    "        for col in missing_cols:\n",
    "            test_df[col] = 0\n",
    "        test_features = test_df[self.X_train.columns]\n",
    "\n",
    "        sales_predictions = self.model.predict(test_features)\n",
    "        sales_predictions = np.where(sales_predictions < 0, 0, sales_predictions)\n",
    "\n",
    "        submission = test_df[[\"id\"]].copy()\n",
    "        submission[\"sales\"] = sales_predictions\n",
    "        submission.to_csv(submission_file, index=False)\n",
    "\n",
    "        print(f\"âœ… Submission saved! Shape: {submission.shape}\")\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        \"\"\"Complete End-to-End Model Training, Evaluation, and Logging.\"\"\"\n",
    "        self.load_data()\n",
    "        self.train_model()\n",
    "        metrics = self.evaluate()\n",
    "        self.log_into_mlflow(metrics)\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cd3c285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-01 20:58:08,048: INFO: main_utils: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-12-01 20:58:08,052: INFO: main_utils: yaml file: params.yaml loaded successfully]\n",
      "[2025-12-01 20:58:08,054: INFO: main_utils: created directory at: artifacts\\model]\n",
      "[2025-12-01 20:58:59,320: INFO: main_utils: json file saved at: evaluation_metrics.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:140: FutureWarning: Filesystem tracking backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
      "  return FileStore(store_uri, store_uri)\n",
      "c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 1177.23it/s]\n",
      "c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\mlflow\\tracking\\_model_registry\\utils.py:215: FutureWarning: Filesystem model registry backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
      "  return FileStore(store_uri)\n",
      "Registered model 'Sales_Forecasting_and_Analytics' already exists. Creating a new version of this model...\n",
      "Created version '4' of model 'Sales_Forecasting_and_Analytics'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Evaluation Done!\n",
      "Metrics saved to evaluation_metrics.json\n",
      "âœ… Submission saved! Shape: (28512, 2)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_manager = ConfigurationManager(CONFIG_FILE_PATH, PARAMS_FILE_PATH)\n",
    "    model_and_eval_config = config_manager.get_modelBuilding_and_evaluation_config()\n",
    "\n",
    "    process = ModelBuildingAndEvaluation(model_and_eval_config)\n",
    "\n",
    "    metrics = process.run_pipeline()\n",
    "    print(f\"âœ… Evaluation Done!\\nMetrics saved to {model_and_eval_config.metrics_file}\")\n",
    "\n",
    "    process.create_submission(model_and_eval_config.input_test_file, \"submission_XgBoost_model2.csv\")\n",
    "\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f173f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salesforecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
