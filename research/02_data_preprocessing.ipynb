{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f12f68",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abd59f2",
   "metadata": {},
   "source": [
    "<p> First we will Load the data using data Loader </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16527232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\MyCase\\\\Projects\\\\DSAI\\\\portfolio\\\\Sales_Forecasting_and_Analytics\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad15882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\MyCase\\\\Projects\\\\DSAI\\\\portfolio\\\\Sales_Forecasting_and_Analytics'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be1cce",
   "metadata": {},
   "source": [
    "<p> Loading the Data </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6fcab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\rosha\\AppData\\Local\\Temp\\ipykernel_1292\\1362580492.py\", line 2, in <module>\n",
      "    from ml_service.components.data_loader import DataLoader\n",
      "ImportError: cannot import name 'DataLoader' from 'ml_service.components.data_loader' (d:\\MyCase\\Projects\\DSAI\\portfolio\\Sales_Forecasting_and_Analytics\\ml_service\\components\\data_loader.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2194, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1188, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1059, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 867, in structured_traceback\n",
      "    formatted_exceptions: list[list[str]] = self.format_exception_as_a_whole(\n",
      "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 779, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 655, in format_record\n",
      "    frame_info.lines,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\IPython\\core\\tbtools.py\", line 355, in lines\n",
      "    return self._sd.lines  # type: ignore[misc]\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\stack_data\\core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\stack_data\\core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\stack_data\\core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "                      ^^^^^^^^^^^^\n",
      "AttributeError: 'Source' object has no attribute 'asttext'\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from ml_service.components.data_ingestion import DataLoader\n",
    "from ml_service.config.configuration import ConfigurationManager\n",
    "from ml_service.constants import *\n",
    "\n",
    "config_manager = ConfigurationManager(CONFIG_FILE_PATH)\n",
    "data_acquisition_config = config_manager.get_data_acquisition_config()\n",
    "\n",
    "loader = DataLoader(\n",
    "    data_dir=Path(data_acquisition_config.local_dir),\n",
    "    source=data_acquisition_config.source,\n",
    "    data_files=data_acquisition_config.data_files,\n",
    "    dataset_name=data_acquisition_config.dataset_name\n",
    ")\n",
    "\n",
    "loader.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f021f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Loading: artifacts\\data_acquisition\\train.csv\n",
      "ðŸ“¥ Loading: artifacts\\data_acquisition\\test.csv\n",
      "ðŸ“¥ Loading: artifacts\\data_acquisition\\stores.csv\n",
      "ðŸ“¥ Loading: artifacts\\data_acquisition\\oil.csv\n",
      "ðŸ“¥ Loading: artifacts\\data_acquisition\\holidays_events.csv\n",
      "ðŸ“¥ Loading: artifacts\\data_acquisition\\transactions.csv\n"
     ]
    }
   ],
   "source": [
    "train_df = loader.load(\"train\")\n",
    "test_df = loader.load(\"test\")\n",
    "stores_df = loader.load(\"stores\")\n",
    "oil_df = loader.load(\"oil\")\n",
    "holidays_events_df = loader.load(\"holidays_events\")\n",
    "transactions_df = loader.load(\"transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8eadb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  store_nbr      family  sales  onpromotion\n",
       "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0\n",
       "1   1  2013-01-01          1   BABY CARE    0.0            0\n",
       "2   2  2013-01-01          1      BEAUTY    0.0            0\n",
       "3   3  2013-01-01          1   BEVERAGES    0.0            0\n",
       "4   4  2013-01-01          1       BOOKS    0.0            0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1114713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000889</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000890</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000891</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000892</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        date  store_nbr      family  onpromotion\n",
       "0  3000888  2017-08-16          1  AUTOMOTIVE            0\n",
       "1  3000889  2017-08-16          1   BABY CARE            0\n",
       "2  3000890  2017-08-16          1      BEAUTY            2\n",
       "3  3000891  2017-08-16          1   BEVERAGES           20\n",
       "4  3000892  2017-08-16          1       BOOKS            0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf40165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataPreprocessingConfig:\n",
    "    \"\"\"Config for preprocessing data.\"\"\"\n",
    "    root_dir: Path\n",
    "    train_file: Path\n",
    "    test_file: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b03a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_service.constants import *\n",
    "from ml_service.utils.main_utils import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51de277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath: str):\n",
    "        \"\"\"Initialize the configuration manager.\n",
    "\n",
    "        Args:\n",
    "            config_filepath (str): Path to the main configuration file (YAML).\n",
    "        \"\"\"\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_preprocessing_config(self) -> DataPreprocessingConfig:\n",
    "        \"\"\"Get the configuration for data preprocessing.\n",
    "\n",
    "        Returns:\n",
    "            DataPreprocessingConfig: Paths for train and test preprocessed files.\n",
    "        \"\"\"\n",
    "        config = self.config.data_preprocessing\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        return DataPreprocessingConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            train_file=Path(config.root_dir) / config.train_file,\n",
    "            test_file=Path(config.root_dir) / config.test_file\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d01b41",
   "metadata": {},
   "source": [
    "<p>Letâ€™s merge the train, stores, and transactions data (and similarly for the test set) for better clarity.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dbb03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merge_df = train_df.merge(stores_df, on='store_nbr', how='left')\n",
    "train_merge_df = train_merge_df.merge(transactions_df, on=['store_nbr','date'], how='left')\n",
    "\n",
    "test_merge_df = test_df.merge(stores_df, on='store_nbr', how='left')\n",
    "test_merge_df = test_merge_df.merge(transactions_df, on=['store_nbr','date'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a35197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  store_nbr      family  sales  onpromotion   city  \\\n",
       "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0  Quito   \n",
       "1   1  2013-01-01          1   BABY CARE    0.0            0  Quito   \n",
       "2   2  2013-01-01          1      BEAUTY    0.0            0  Quito   \n",
       "3   3  2013-01-01          1   BEVERAGES    0.0            0  Quito   \n",
       "4   4  2013-01-01          1       BOOKS    0.0            0  Quito   \n",
       "\n",
       "       state type  cluster  transactions  \n",
       "0  Pichincha    D       13           NaN  \n",
       "1  Pichincha    D       13           NaN  \n",
       "2  Pichincha    D       13           NaN  \n",
       "3  Pichincha    D       13           NaN  \n",
       "4  Pichincha    D       13           NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a221b572",
   "metadata": {},
   "source": [
    "<p>Now, Letâ€™s merge the holidays_events and oil data (and similarly for the test set) for Date-level features.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbd06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_events_oil_merge_df = oil_df.merge(holidays_events_df, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a206049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>type</th>\n",
       "      <th>locale</th>\n",
       "      <th>locale_name</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>93.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>92.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>93.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>93.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  dcoilwtico     type    locale locale_name         description  \\\n",
       "0  2013-01-01         NaN  Holiday  National     Ecuador  Primer dia del ano   \n",
       "1  2013-01-02       93.14      NaN       NaN         NaN                 NaN   \n",
       "2  2013-01-03       92.97      NaN       NaN         NaN                 NaN   \n",
       "3  2013-01-04       93.12      NaN       NaN         NaN                 NaN   \n",
       "4  2013-01-07       93.20      NaN       NaN         NaN                 NaN   \n",
       "\n",
       "  transferred  \n",
       "0       False  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holidays_events_oil_merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e5a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = train_merge_df.merge(holidays_events_oil_merge_df, on='date', how='left')\n",
    "test_final = test_merge_df.merge(holidays_events_oil_merge_df, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb1c398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type_x</th>\n",
       "      <th>cluster</th>\n",
       "      <th>transactions</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>type_y</th>\n",
       "      <th>locale</th>\n",
       "      <th>locale_name</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  store_nbr      family  sales  onpromotion   city  \\\n",
       "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0  Quito   \n",
       "1   1  2013-01-01          1   BABY CARE    0.0            0  Quito   \n",
       "2   2  2013-01-01          1      BEAUTY    0.0            0  Quito   \n",
       "3   3  2013-01-01          1   BEVERAGES    0.0            0  Quito   \n",
       "4   4  2013-01-01          1       BOOKS    0.0            0  Quito   \n",
       "\n",
       "       state type_x  cluster  transactions  dcoilwtico   type_y    locale  \\\n",
       "0  Pichincha      D       13           NaN         NaN  Holiday  National   \n",
       "1  Pichincha      D       13           NaN         NaN  Holiday  National   \n",
       "2  Pichincha      D       13           NaN         NaN  Holiday  National   \n",
       "3  Pichincha      D       13           NaN         NaN  Holiday  National   \n",
       "4  Pichincha      D       13           NaN         NaN  Holiday  National   \n",
       "\n",
       "  locale_name         description transferred  \n",
       "0     Ecuador  Primer dia del ano       False  \n",
       "1     Ecuador  Primer dia del ano       False  \n",
       "2     Ecuador  Primer dia del ano       False  \n",
       "3     Ecuador  Primer dia del ano       False  \n",
       "4     Ecuador  Primer dia del ano       False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef76ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "date                  0\n",
       "store_nbr             0\n",
       "family                0\n",
       "sales                 0\n",
       "onpromotion           0\n",
       "city                  0\n",
       "state                 0\n",
       "type_x                0\n",
       "cluster               0\n",
       "transactions     248358\n",
       "dcoilwtico       933768\n",
       "type_y          2680128\n",
       "locale          2680128\n",
       "locale_name     2680128\n",
       "description     2680128\n",
       "transferred     2680128\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5103c393",
   "metadata": {},
   "source": [
    "###  Dropping Lowâ€‘Value Features\n",
    "\n",
    "We drop the following columns:\n",
    "\n",
    "* **`description`**, **`locale_name`**, **`locale`**, and **`transferred`**\n",
    "\n",
    "#### âœ… Why?\n",
    "\n",
    "* These fields contain textual or highly sparse information that **doesnâ€™t directly affect sales prediction**.\n",
    "* They introduce **noise** and **high cardinality**, making it harder for the model to learn meaningful patterns.\n",
    "* Similar information (holidays) is already captured by the **`type`** column, making these redundant.\n",
    "\n",
    "#### ðŸ’¡ Result\n",
    "\n",
    "By removing these columns, we:\n",
    "\n",
    "* **Improve training efficiency** (smaller, cleaner dataset).\n",
    "* Reduce the risk of overfitting.\n",
    "* Maintain focus on the features that matter for forecasting sales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b74e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final.drop(columns=['description', 'locale_name', 'locale', 'transferred'], inplace=True)\n",
    "test_final.drop(columns=['description', 'locale_name', 'locale', 'transferred'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f07f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type_x</th>\n",
       "      <th>cluster</th>\n",
       "      <th>transactions</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>type_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  store_nbr      family  sales  onpromotion   city  \\\n",
       "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0  Quito   \n",
       "1   1  2013-01-01          1   BABY CARE    0.0            0  Quito   \n",
       "2   2  2013-01-01          1      BEAUTY    0.0            0  Quito   \n",
       "3   3  2013-01-01          1   BEVERAGES    0.0            0  Quito   \n",
       "4   4  2013-01-01          1       BOOKS    0.0            0  Quito   \n",
       "\n",
       "       state type_x  cluster  transactions  dcoilwtico   type_y  \n",
       "0  Pichincha      D       13           NaN         NaN  Holiday  \n",
       "1  Pichincha      D       13           NaN         NaN  Holiday  \n",
       "2  Pichincha      D       13           NaN         NaN  Holiday  \n",
       "3  Pichincha      D       13           NaN         NaN  Holiday  \n",
       "4  Pichincha      D       13           NaN         NaN  Holiday  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dc43bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3032964, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2492906d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "date                  0\n",
       "store_nbr             0\n",
       "family                0\n",
       "sales                 0\n",
       "onpromotion           0\n",
       "city                  0\n",
       "state                 0\n",
       "type_x                0\n",
       "cluster               0\n",
       "transactions     248358\n",
       "dcoilwtico       933768\n",
       "type_y          2680128\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8f0a08",
   "metadata": {},
   "source": [
    "<p> We impute transactions due to its high predictive potential, while dropping columns with excessive sparsity and low information value. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c72973",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final[\"dcoilwtico\"] = train_final[\"dcoilwtico\"].interpolate(method=\"linear\")\n",
    "train_final[\"dcoilwtico\"] = train_final[\"dcoilwtico\"].interpolate(method=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2fd4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "date                  0\n",
       "store_nbr             0\n",
       "family                0\n",
       "sales                 0\n",
       "onpromotion           0\n",
       "city                  0\n",
       "state                 0\n",
       "type_x                0\n",
       "cluster               0\n",
       "transactions     248358\n",
       "dcoilwtico         1782\n",
       "type_y          2680128\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7965bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phoen\\AppData\\Local\\Temp\\ipykernel_20352\\1786350395.py:1: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_final['dcoilwtico'] = train_final['dcoilwtico'].fillna(method='ffill')\n",
      "C:\\Users\\phoen\\AppData\\Local\\Temp\\ipykernel_20352\\1786350395.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test_final['dcoilwtico'] = test_final['dcoilwtico'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "train_final['dcoilwtico'] = train_final['dcoilwtico'].fillna(method='ffill')\n",
    "test_final['dcoilwtico'] = test_final['dcoilwtico'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d767f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "date                  0\n",
       "store_nbr             0\n",
       "family                0\n",
       "sales                 0\n",
       "onpromotion           0\n",
       "city                  0\n",
       "state                 0\n",
       "type_x                0\n",
       "cluster               0\n",
       "transactions     248358\n",
       "dcoilwtico         1782\n",
       "type_y          2680128\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9decf37",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82731425",
   "metadata": {},
   "source": [
    "Note: Since transactions is the only column with missing values, we'll apply an imputation technique (such as filling with median or other suitable method) during the Data Transformation phase, where we'll also handle scaling, encoding, and splitting of the dataset. This ensures a clean and robust workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90870d7d",
   "metadata": {},
   "source": [
    "<p>Now Let's look for duplicate values and handle them </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1170e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14256"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cb04bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a5691",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25500f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4958a3",
   "metadata": {},
   "source": [
    "<p>Since the data is clean  with no duplicate rows and no significant missing values (other than the <code>transactions</code> column, which we'll impute later) we can now move on to the next phase of the pipeline.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afa159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"Perform merging, cleaning, and exporting of Store Sales Time Series data.\"\"\"\n",
    "\n",
    "    def __init__(self, data_dir: Path, data_files: Dict[str, str]) -> None:\n",
    "        self.data_dir = data_dir\n",
    "        self.data_files = data_files\n",
    "        self.data = {}\n",
    "\n",
    "    def load(self) -> \"DataProcessor\":\n",
    "        \"\"\"Load all files and standardize date columns.\"\"\"\n",
    "        self.data = {\n",
    "            name: pd.read_csv(self.data_dir / path) for name, path in self.data_files.items()\n",
    "        }\n",
    "        # âœ… Ensure 'date' columns are ALWAYS datetime\n",
    "        for key in [\"train\", \"test\", \"oil\", \"holidays_events\", \"transactions\"]:\n",
    "            if key in self.data and \"date\" in self.data[key].columns:\n",
    "                self.data[key][\"date\"] = pd.to_datetime(self.data[key][\"date\"])\n",
    "        return self\n",
    "\n",
    "    def interpolate_oil(self) -> \"DataProcessor\":\n",
    "        \"\"\"Interpolate missing values in the oil data.\"\"\"\n",
    "        self.data[\"oil\"].set_index(\"date\", inplace=True)\n",
    "        self.data[\"oil\"][\"dcoilwtico\"] = self.data[\"oil\"][\"dcoilwtico\"].interpolate(method=\"linear\")\n",
    "        self.data[\"oil\"].reset_index(inplace=True)\n",
    "        return self\n",
    "\n",
    "    def merge_train_test(self) -> \"DataProcessor\":\n",
    "        \"\"\"Merge train/test with stores and transactions.\"\"\"\n",
    "        self.data[\"train_merged\"] = (\n",
    "            self.data[\"train\"]\n",
    "            .merge(self.data[\"stores\"], on=\"store_nbr\", how=\"left\")\n",
    "            .merge(self.data[\"transactions\"], on=[\"store_nbr\", \"date\"], how=\"left\")\n",
    "        )\n",
    "        self.data[\"test_merged\"] = (\n",
    "            self.data[\"test\"]\n",
    "            .merge(self.data[\"stores\"], on=\"store_nbr\", how=\"left\")\n",
    "            .merge(self.data[\"transactions\"], on=[\"store_nbr\", \"date\"], how=\"left\")\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def merge_holidays_and_oil(self) -> \"DataProcessor\":\n",
    "        \"\"\"Merge holidays and oil data for final train/test.\"\"\"\n",
    "        holidays_oil_merged = self.data[\"oil\"].merge(self.data[\"holidays_events\"], on=\"date\", how=\"left\")\n",
    "\n",
    "        self.data[\"train_final\"] = self.data[\"train_merged\"].merge(holidays_oil_merged, on=\"date\", how=\"left\")\n",
    "        self.data[\"test_final\"] = self.data[\"test_merged\"].merge(holidays_oil_merged, on=\"date\", how=\"left\")\n",
    "\n",
    "        # Final interpolate + forward fill\n",
    "        for df_name in [\"train_final\", \"test_final\"]:\n",
    "            self.data[df_name][\"dcoilwtico\"] = (\n",
    "                self.data[df_name][\"dcoilwtico\"].interpolate(method=\"linear\").ffill()\n",
    "            )\n",
    "        return self\n",
    "\n",
    "    def drop_irrelevant_columns(self) -> \"DataProcessor\":\n",
    "        \"\"\"Drop low-value and sparse columns, remove duplicates.\"\"\"\n",
    "        drop_cols = [\"description\", \"locale_name\", \"locale\", \"transferred\"]\n",
    "        for df_name in [\"train_final\", \"test_final\"]:\n",
    "            self.data[df_name].drop(columns=drop_cols, errors=\"ignore\", inplace=True)\n",
    "            self.data[df_name].drop_duplicates(inplace=True)\n",
    "        return self\n",
    "\n",
    "    def save(self, train_file: Path, test_file: Path) -> \"DataProcessor\":\n",
    "        \"\"\"Save final merged train and test files.\"\"\"\n",
    "        train_file.parent.mkdir(parents=True, exist_ok=True) \n",
    "        self.data[\"train_final\"].to_csv(train_file, index=False)\n",
    "        self.data[\"test_final\"].to_csv(test_file, index=False)\n",
    "\n",
    "        print(f\"âœ… Final train saved to: {train_file}\")\n",
    "        print(f\"âœ… Final test saved to: {test_file}\")\n",
    "\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3481c2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-26 00:45:54,741: INFO: main_utils: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-06-26 00:45:54,744: INFO: main_utils: created directory at: artifacts]\n",
      "[2025-06-26 00:45:54,747: INFO: main_utils: created directory at: artifacts/data_acquisition]\n",
      "[2025-06-26 00:45:54,749: INFO: main_utils: created directory at: artifacts/data_preprocessing]\n",
      "âœ… Final train saved to: artifacts\\data_preprocessing\\train_merged.csv\n",
      "âœ… Final test saved to: artifacts\\data_preprocessing\\test_merged.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.DataProcessor at 0x28e20b73820>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from ml_service.config.configuration import ConfigurationManager\n",
    "from ml_service.constants import CONFIG_FILE_PATH\n",
    "\n",
    "config_manager = ConfigurationManager(CONFIG_FILE_PATH)\n",
    "data_acquisition_config = config_manager.get_data_acquisition_config()\n",
    "data_preprocessing_config = config_manager.get_data_preprocessing_config()\n",
    "\n",
    "data_dir = Path(data_acquisition_config.local_dir)\n",
    "files = data_acquisition_config.data_files\n",
    "\n",
    "DataProcessor(data_dir, files) \\\n",
    "    .load() \\\n",
    "    .interpolate_oil() \\\n",
    "    .merge_train_test() \\\n",
    "    .merge_holidays_and_oil() \\\n",
    "    .drop_irrelevant_columns() \\\n",
    "    .save(data_preprocessing_config.train_file, data_preprocessing_config.test_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salesforecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
