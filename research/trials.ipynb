{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "640aadb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\MyCase\\\\Projects\\\\DSAI\\\\portfolio\\\\Sales_Forecasting_and_Analytics\\\\artifacts\\\\features_dataTransformation'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "os.chdir(\"./artifacts/features_dataTransformation/\")\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac0dc982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"train_final.csv\")\n",
    "test_df = pd.read_csv(\"test_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "324d31d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"transactions\"] = train_df[\"transactions\"].fillna(0)  \n",
    "test_df[\"transactions\"] = test_df[\"transactions\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bd40c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['id', 'date', 'store_nbr', 'family', 'sales', 'onpromotion', 'city',\n",
       "        'state', 'type_x', 'cluster',\n",
       "        ...\n",
       "        'city_Santo Domingo', 'type_x_B', 'type_x_C', 'type_x_D', 'type_x_E',\n",
       "        'type_y_Bridge', 'type_y_Event', 'type_y_Holiday', 'type_y_Regular Day',\n",
       "        'type_y_Transfer'],\n",
       "       dtype='object', length=101),\n",
       " Index(['id', 'date', 'store_nbr', 'family', 'sales', 'onpromotion', 'city',\n",
       "        'state', 'type_x', 'cluster',\n",
       "        ...\n",
       "        'city_Santo Domingo', 'type_x_B', 'type_x_C', 'type_x_D', 'type_x_E',\n",
       "        'type_y_Bridge', 'type_y_Event', 'type_y_Holiday', 'type_y_Regular Day',\n",
       "        'type_y_Transfer'],\n",
       "       dtype='object', length=101))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns, test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5955db1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3013362, 101), (28512, 101))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baa97e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_Imbabura</th>\n",
       "      <th>state_Imbabura</th>\n",
       "      <th>family_PRODUCE</th>\n",
       "      <th>family_PRODUCE</th>\n",
       "      <th>state_Guayas</th>\n",
       "      <th>state_Guayas</th>\n",
       "      <th>city_Cuenca</th>\n",
       "      <th>city_Cuenca</th>\n",
       "      <th>family_PET SUPPLIES</th>\n",
       "      <th>family_PET SUPPLIES</th>\n",
       "      <th>...</th>\n",
       "      <th>state_Manabi</th>\n",
       "      <th>state_Manabi</th>\n",
       "      <th>month</th>\n",
       "      <th>type_y_Regular Day</th>\n",
       "      <th>type_y_Regular Day</th>\n",
       "      <th>family_LAWN AND GARDEN</th>\n",
       "      <th>family_LAWN AND GARDEN</th>\n",
       "      <th>family_HOME AND KITCHEN II</th>\n",
       "      <th>family_HOME AND KITCHEN II</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_Imbabura  state_Imbabura  family_PRODUCE  family_PRODUCE  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "\n",
       "   state_Guayas  state_Guayas  city_Cuenca  city_Cuenca  family_PET SUPPLIES  \\\n",
       "0             0             0            0            0                    0   \n",
       "1             0             0            0            0                    0   \n",
       "\n",
       "   family_PET SUPPLIES  ...  state_Manabi  state_Manabi  month  \\\n",
       "0                    0  ...             0             0      1   \n",
       "1                    0  ...             0             0      1   \n",
       "\n",
       "   type_y_Regular Day  type_y_Regular Day  family_LAWN AND GARDEN  \\\n",
       "0                   0                   0                       0   \n",
       "1                   0                   0                       0   \n",
       "\n",
       "   family_LAWN AND GARDEN  family_HOME AND KITCHEN II  \\\n",
       "0                       0                           0   \n",
       "1                       0                           0   \n",
       "\n",
       "   family_HOME AND KITCHEN II  sales  \n",
       "0                           0    0.0  \n",
       "1                           0    0.0  \n",
       "\n",
       "[2 rows x 175 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d2b99b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['family' 'state' 'city' 'type_x' 'type_y' 'sales'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_18964\\12976098.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m     61\u001b[39m cat_columns = [\u001b[33m\"family\"\u001b[39m, \u001b[33m\"state\"\u001b[39m, \u001b[33m\"city\"\u001b[39m, \u001b[33m\"type_x\"\u001b[39m, \u001b[33m\"type_y\"\u001b[39m, \u001b[33m\"sales\"\u001b[39m]\n\u001b[32m     62\u001b[39m target_col = \u001b[33m\"sales\"\u001b[39m   \u001b[38;5;66;03m# or whatever target is\u001b[39;00m\n\u001b[32m     63\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m X_train = train_features.drop(columns=cat_columns, axis=\u001b[32m1\u001b[39m)\n\u001b[32m     65\u001b[39m y_train = train_features[target_col]\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# {'subsample': 0.8, 'reg_lambda': 2, 'reg_alpha': 0.1, 'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.05, 'gamma': 0, 'colsample_bytree': 0.6}\u001b[39;00m\n\u001b[32m     67\u001b[39m \n",
      "\u001b[32mc:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5599\u001b[39m                 weight  \u001b[32m250.0\u001b[39m   \u001b[32m150.0\u001b[39m\n\u001b[32m   5600\u001b[39m         falcon  speed   \u001b[32m320.0\u001b[39m   \u001b[32m250.0\u001b[39m\n\u001b[32m   5601\u001b[39m                 weight  \u001b[32m1.0\u001b[39m     \u001b[32m0.8\u001b[39m\n\u001b[32m   5602\u001b[39m         \"\"\"\n\u001b[32m-> \u001b[39m\u001b[32m5603\u001b[39m         return super().drop(\n\u001b[32m   5604\u001b[39m             labels=labels,\n\u001b[32m   5605\u001b[39m             axis=axis,\n\u001b[32m   5606\u001b[39m             index=index,\n",
      "\u001b[32mc:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4806\u001b[39m         obj = self\n\u001b[32m   4807\u001b[39m \n\u001b[32m   4808\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;28;01min\u001b[39;00m axes.items():\n\u001b[32m   4809\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4810\u001b[39m                 obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n\u001b[32m   4811\u001b[39m \n\u001b[32m   4812\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4813\u001b[39m             self._update_inplace(obj)\n",
      "\u001b[32mc:\\Users\\rosha\\anaconda3\\envs\\salesforecast\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4877\u001b[39m                 mask = ~axis.isin(labels)\n\u001b[32m   4878\u001b[39m                 \u001b[38;5;66;03m# Check if label doesn't exist along axis\u001b[39;00m\n\u001b[32m   4879\u001b[39m                 labels_missing = (axis.get_indexer_for(labels) == -\u001b[32m1\u001b[39m).any()\n\u001b[32m   4880\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"raise\"\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m labels_missing:\n\u001b[32m-> \u001b[39m\u001b[32m4881\u001b[39m                     \u001b[38;5;28;01mraise\u001b[39;00m KeyError(f\"{labels} not found in axis\")\n\u001b[32m   4882\u001b[39m \n\u001b[32m   4883\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m isinstance(mask.dtype, ExtensionDtype):\n\u001b[32m   4884\u001b[39m                 \u001b[38;5;66;03m# GH#45860\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: \"['family' 'state' 'city' 'type_x' 'type_y' 'sales'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "# Fill missing values\n",
    "train_df[\"transactions\"] = train_df[\"transactions\"].fillna(0)\n",
    "test_df[\"transactions\"] = test_df[\"transactions\"].fillna(0)\n",
    "train_df[\"type_y\"] = train_df[\"type_y\"].fillna(\"Regular Day\")\n",
    "test_df[\"type_y\"] = test_df[\"type_y\"].fillna(\"Regular Day\")\n",
    "train_df[\"dcoilwtico\"] = train_df[\"dcoilwtico\"].bfill()\n",
    "test_df[\"dcoilwtico\"] = test_df[\"dcoilwtico\"].bfill()\n",
    "\n",
    "# Parse date and extract features\n",
    "for df in [train_df, test_df]:\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"year\"] = df[\"date\"].dt.year\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "    df[\"day\"] = df[\"date\"].dt.day\n",
    "    df[\"day_of_week\"] = df[\"date\"].dt.dayofweek\n",
    "    df[\"is_weekend\"] = (df[\"day_of_week\"] >= 5).astype(int)\n",
    "    df[\"day_of_year\"] = df[\"date\"].dt.dayofyear\n",
    "    df[\"is_month_start\"] = df[\"date\"].dt.is_month_start.astype(int)\n",
    "    df[\"is_month_end\"] = df[\"date\"].dt.is_month_end.astype(int)\n",
    "\n",
    "# Interactions\n",
    "train_df[\"onpromotion_trend\"] = train_df[\"onpromotion\"] * train_df[\"day_of_year\"]\n",
    "test_df[\"onpromotion_trend\"] = test_df[\"onpromotion\"] * test_df[\"day_of_year\"]\n",
    "train_df[\"month_sales_interaction\"] = train_df[\"month\"] * train_df[\"sales\"]\n",
    "\n",
    "# One-hot encode\n",
    "cat_cols = [\"family\", \"state\", \"city\", \"type_x\", \"type_y\"]\n",
    "# train_df = pd.get_dummies(train_df, columns=cat_cols, drop_first=True, dtype=int)\n",
    "# test_df = pd.get_dummies(test_df, columns=cat_cols, drop_first=True, dtype=int)\n",
    "\n",
    "encoded = pd.get_dummies(train_df[cat_cols], drop_first=True, dtype=int)\n",
    "train_df = pd.concat([train_df, encoded], axis=1)\n",
    "\n",
    "encoded = pd.get_dummies(test_df[cat_cols], drop_first=True, dtype=int)\n",
    "test_df = pd.concat([test_df, encoded], axis=1)\n",
    "\n",
    "# Align columns\n",
    "common_cols = set(train_df.columns) & set(test_df.columns)\n",
    "train_features = train_df[list(common_cols) + [\"sales\"]]\n",
    "test_features = test_df[list(common_cols)]\n",
    "\n",
    "# Scale selected features\n",
    "scale_cols = [\"onpromotion\", \"transactions\", \"dcoilwtico\", \"onpromotion_trend\"]\n",
    "scaler = MinMaxScaler()\n",
    "train_features[scale_cols] = scaler.fit_transform(train_features[scale_cols])\n",
    "test_features[scale_cols] = scaler.transform(test_features[scale_cols])\n",
    "\n",
    "# Drop non-numeric columns\n",
    "train_features = train_features.select_dtypes(include=[np.number])\n",
    "test_features = test_features.select_dtypes(include=[np.number])\n",
    "\n",
    "# Train model\n",
    "cat_columns = [\"family\", \"state\", \"city\", \"type_x\", \"type_y\", \"sales\"]\n",
    "target_col = \"sales\"   # or whatever target is\n",
    "\n",
    "X_train = train_features.drop(columns=cat_columns, axis=1)\n",
    "y_train = train_features[target_col]\n",
    "# {'subsample': 0.8, 'reg_lambda': 2, 'reg_alpha': 0.1, 'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.05, 'gamma': 0, 'colsample_bytree': 0.6}\n",
    "\n",
    "model = XGBRegressor(n_estimators=500, \n",
    "                     learning_rate=0.05, \n",
    "                     max_depth=7, \n",
    "                     subsample=0.8, \n",
    "                     colsample_bytree=0.6, \n",
    "                     reg_alpha=0.1, \n",
    "                     reg_lambda=2, \n",
    "                     gamma=0, \n",
    "                     random_state=42)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on train (no val split here)\n",
    "y_pred = model.predict(X_train)\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "\n",
    "# üëá RMSLE Evaluation\n",
    "rmsle = np.sqrt(np.mean((np.log1p(y_train) - np.log1p(y_pred)) ** 2))\n",
    "\n",
    "print(\"‚úÖ Training Evaluation:\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE : {mae:.4f}\")\n",
    "print(f\"R2  : {r2:.4f}\")\n",
    "print(f\"RMSLE: {rmsle:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f7e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Train CatBoost model with similar hyperparameters\n",
    "catboost_model = CatBoostRegressor(\n",
    "  iterations=1000,\n",
    "  learning_rate=0.05,\n",
    "  depth=7,\n",
    "  subsample=0.8,\n",
    "  colsample_bylevel=0.6,\n",
    "  reg_lambda=2,\n",
    "  random_seed=42,\n",
    "  verbose=0\n",
    ")\n",
    "\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on train set\n",
    "y_pred_cb = catboost_model.predict(X_train)\n",
    "rmse_cb = np.sqrt(mean_squared_error(y_train, y_pred_cb))\n",
    "mae_cb = mean_absolute_error(y_train, y_pred_cb)\n",
    "r2_cb = r2_score(y_train, y_pred_cb)\n",
    "rmsle_cb = np.sqrt(np.mean((np.log1p(y_train) - np.log1p(y_pred_cb)) ** 2))\n",
    "\n",
    "print(\"‚úÖ CatBoost Training Evaluation:\")\n",
    "print(f\"RMSE: {rmse_cb:.4f}\")\n",
    "print(f\"MAE : {mae_cb:.4f}\")\n",
    "print(f\"R2  : {r2_cb:.4f}\")\n",
    "print(f\"RMSLE: {rmsle_cb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dc16ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "test_df[\"sales\"] = catboost_model.predict(test_features)\n",
    "\n",
    "# Ensure no negative predictions\n",
    "test_df[\"sales\"] = test_df[\"sales\"].clip(lower=0)\n",
    "\n",
    "# Prepare submission\n",
    "submission = test_df[[\"id\", \"sales\"]].copy()\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"‚úÖ submission.csv saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb75ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def get_best_hyperparameters(X, y, n_iter=30, cv=3, random_state=42, verbose=1):\n",
    "    \"\"\"Performs hyperparameter tuning using RandomizedSearchCV for XGBRegressor.\"\"\"\n",
    "    \n",
    "    param_dist = {\n",
    "        \"n_estimators\": [100, 300, 500, 700],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 5, 7, 10],\n",
    "        \"subsample\": [0.6, 0.8, 1.0],\n",
    "        \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "        \"gamma\": [0, 0.1, 0.3, 0.5],\n",
    "        \"reg_alpha\": [0, 0.1, 0.5],\n",
    "        \"reg_lambda\": [1, 1.5, 2]\n",
    "    }\n",
    "\n",
    "    xgb = XGBRegressor(objective=\"reg:squarederror\", random_state=random_state)\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=xgb,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        verbose=verbose,\n",
    "        n_jobs=-1,\n",
    "        scoring='neg_root_mean_squared_error'\n",
    "    )\n",
    "\n",
    "    print(\"üîç Searching for best hyperparameters...\")\n",
    "    random_search.fit(X, y)\n",
    "    print(\"‚úÖ Best Hyperparameters Found!\")\n",
    "    print(random_search.best_params_)\n",
    "\n",
    "    return random_search.best_estimator_, random_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67a2c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call hyperparameter tuning\n",
    "best_model, best_params = get_best_hyperparameters(X_train, y_train)\n",
    "\n",
    "# Predict on test features\n",
    "test_df[\"sales\"] = best_model.predict(test_features).clip(lower=0)\n",
    "submission = test_df[[\"id\", \"sales\"]]\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332d9e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "test_df[\"sales\"] = model.predict(test_features)\n",
    "\n",
    "# Ensure no negative predictions\n",
    "test_df[\"sales\"] = test_df[\"sales\"].clip(lower=0)\n",
    "\n",
    "# Prepare submission\n",
    "submission = test_df[[\"id\", \"sales\"]].copy()\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"‚úÖ submission.csv saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salesforecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
